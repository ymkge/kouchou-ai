import sys
from pathlib import Path

# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰3éšå±¤ä¸Šã® server/ ã‚’ PYTHONPATH ã«è¿½åŠ 
root_path = Path(__file__).resolve().parents[3] / "server"
sys.path.insert(0, str(root_path))

import argparse
import json
from pathlib import Path

import pandas as pd
from broadlistening.pipeline.services.llm import request_to_chat_openai


def get_criteria_clarity() -> str:
    return """Clarityï¼ˆæ˜ç¢ºã•ï¼‰
è©•ä¾¡å¯¾è±¡: ãƒ©ãƒ™ãƒ«ãŠã‚ˆã³èª¬æ˜æ–‡

1ç‚¹: ä½•ã‚’ä¼ãˆãŸã„ã®ã‹ã»ã¨ã‚“ã©ã‚ã‹ã‚‰ãªã„ã€‚ä¸»èªãƒ»è¿°èªãŒã‚ã„ã¾ã„ã§ã€æ„å›³ãŒä¸æ˜ã€‚
2ç‚¹: ä¸»æ—¨ã¯æ´ã‚ã‚‹ãŒæ›–æ˜§ãªè¡¨ç¾ã‚„å†—é•·ã•ãŒã‚ã‚Šã€æ¨æ¸¬ãŒå¿…è¦ã€‚
3ç‚¹: ãŠãŠã‚€ã­æ„å›³ã¯æ˜ç¢ºã ãŒã€æƒ…å ±ã®éä¸è¶³ã‚„è¡¨ç¾ã®ã¶ã‚ŒãŒã‚ã‚‹ã€‚
4ç‚¹: è»½å¾®ãªæ›–æ˜§ã•ã®ã¿ã§ã€ã»ã¨ã‚“ã©ã®ç®‡æ‰€ã§æ˜ç¢ºã«ä¼ã‚ã‚‹ã€‚
5ç‚¹: ä¸€èª­ã§å®Œå…¨ã«æ„å›³ãŒä¼ã‚ã‚Šã€èª¤è§£ã®ä½™åœ°ãŒãªã„ã€‚
"""


def get_criteria_coherence() -> str:
    return """Coherenceï¼ˆä¸€è²«æ€§ï¼‰
è©•ä¾¡å¯¾è±¡: ãƒ©ãƒ™ãƒ«ãŠã‚ˆã³èª¬æ˜æ–‡

1ç‚¹: è«–ç†ã®ã¤ãªãŒã‚ŠãŒä¹ã—ãã€è¦ç´ ãŒãƒãƒ©ãƒãƒ©ã«ä¸¦ã‚“ã§ã„ã‚‹ã€‚
2ç‚¹: æµã‚Œã¯ã‚ã‚‹ãŒã€è©±é¡Œè»¢æ›ã‚„è«–ç†ã®é£›èºãŒç›®ç«‹ã¤ã€‚
3ç‚¹: æ¦‚ã­ã¤ãªãŒã£ã¦ã„ã‚‹ãŒã€ä¸€éƒ¨ã‚ã„ã¾ã„ãªç‚¹ã‚„æ¥ç¶šä¸è¶³ãŒã‚ã‚‹ã€‚
4ç‚¹: è‡ªç„¶ãªæµã‚Œã§å±•é–‹ã•ã‚Œã¦ãŠã‚Šã€å°ã•ãªæ¥ç¶šä¸è¶³ã®ã¿ã€‚
5ç‚¹: è«–ç†çš„ã§ä¸€è²«æ€§ãŒã‚ã‚Šã€æ§‹æˆãŒæ˜ç¢ºã€‚
"""


def get_criteria_distinctiveness() -> str:
    return """Distinctivenessï¼ˆä»–æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã®å·®ç•°ï¼‰
è©•ä¾¡å¯¾è±¡: ãƒ©ãƒ™ãƒ«ãŠã‚ˆã³èª¬æ˜æ–‡ï¼ˆå…¨æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã¾ã¨ã‚ã¦æ¯”è¼ƒï¼‰

1ç‚¹: å†…å®¹ãŒä»–æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã¨å¤§ããé‡è¤‡ã—ã¦ã„ã‚‹ã€‚
2ç‚¹: ä¸€éƒ¨ç‹¬è‡ªè¦ç´ ã¯ã‚ã‚‹ãŒã€åˆ¤åˆ¥ã—ã«ãã„ã€‚
3ç‚¹: ä¸»è¦ãƒ†ãƒ¼ãƒã¯ç‹¬è‡ªã ãŒã€ç´°éƒ¨ã«é‡è¤‡ãŒã‚ã‚‹ã€‚
4ç‚¹: ç‹¬è‡ªæ€§ãŒé«˜ãã€ä»–ã¨åŒºåˆ¥ã—ã‚„ã™ã„ã€‚
5ç‚¹: å®Œå…¨ã«ç‹¬è‡ªã®ãƒ†ãƒ¼ãƒã§ã‚ã‚Šã€æ˜ç¢ºã«åŒºåˆ¥ã§ãã‚‹ã€‚

å…¨ä½“ã‚’é€šã˜ã¦å…±é€šã—ã¦ã„ã‚‹ã€ŒèƒŒæ™¯ã€ã‚„ã€Œå‰æã€ã«ã¤ã„ã¦å‹˜æ¡ˆã—ã€ãã‚Œã‚‰ã‚’å·®ç•°è©•ä¾¡ã®å¯¾è±¡ã‹ã‚‰é™¤å¤–ã—ã¦ãã ã•ã„ã€‚ãã®ã†ãˆã§ã€ä¸»å¼µã‚„è«–ç‚¹ã®é•ã„ã«æ³¨ç›®ã—ã¦æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®å·®ç•°ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€æœ€å¾Œã«distinctiveness_commentã¨ã—ã¦å…¨ä½“ã‚’é€šã—ã¦ã®ã€ŒèƒŒæ™¯ã€ã‚„ã€Œå‰æã€ã€é¡ä¼¼ç‚¹ã€æ”¹å–„æ¡ˆãªã©ç·æ‹¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚ç·æ‹¬ã§ã¯æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—IDã¯ä½¿ç”¨ã›ãšå¿…è¦ãŒã‚ã‚Œã°ãƒ©ãƒ™ãƒ«åã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
"""


def get_criteria_consistency() -> str:
    return """Consistencyï¼ˆæ„è¦‹ã®æ•´åˆåº¦ï¼‰
è©•ä¾¡å¯¾è±¡: ãƒ©ãƒ™ãƒ«ãƒ»èª¬æ˜æ–‡ã¨æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®æ„è¦‹å…¨ä½“

1ç‚¹: èª¬æ˜ãŒæ„è¦‹ã¨å…¨ãé–¢ä¿‚ãªãã€å†…å®¹ãŒä¹–é›¢ã—ã¦ã„ã‚‹ï¼è«–ç†çš„ã«çŸ›ç›¾ã—ã¦ã„ã‚‹ã€‚
2ç‚¹: æ„è¦‹ã®è¦ç‚¹ã«è§¦ã‚Œã¦ã„ã‚‹ãŒã€ç†ç”±ãŒä¸é©åˆ‡ã¾ãŸã¯è«–ç†ã®é£›èºãŒå¤§ãã„ã€‚
3ç‚¹: æ¦‚ã­æ„è¦‹ã¨ä¸€è‡´ã™ã‚‹ãŒã€ä¸€éƒ¨ã«ä¸è‡ªç„¶ãªèª¬æ˜ã‚„è«–ç†ã®æ›–æ˜§ã•ãŒã‚ã‚‹ã€‚
4ç‚¹: æ„è¦‹ã¨èª¬æ˜ãŒæ•´åˆã—ã¦ãŠã‚Šã€å…¨ä½“ã¨ã—ã¦è‡ªç„¶ãªæµã‚Œã«ãªã£ã¦ã„ã‚‹ã€‚
5ç‚¹: æ„è¦‹ã¨èª¬æ˜ãŒå¯†æ¥ã«çµã³ã¤ã„ã¦ãŠã‚Šã€è«–ç†çš„ã«ä¸€è²«ã—ã¦ç´å¾—æ„ŸãŒé«˜ã„ã€‚
"""


def get_prompt_criteria_text(criteria: list[str]) -> str:
    parts = []
    if "clarity" in criteria:
        parts.append(get_criteria_clarity())
    if "coherence" in criteria:
        parts.append(get_criteria_coherence())
    if "distinctiveness" in criteria:
        parts.append(get_criteria_distinctiveness())
    if "consistency" in criteria:
        parts.append(get_criteria_consistency())
    return "\n".join(parts)


def get_prompt_batch() -> str:
    return (
        """ä»¥ä¸‹ã®æŒ‡æ¨™ã«ã¤ã„ã¦ã€å„æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ 1ã€œ5 ç‚¹ã§è©•ä¾¡ã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã¯ä¸‹è¨˜ã®åŸºæº–ã«æ²¿ã£ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚ä¸€è¦‹ã‚¨ãƒ©ãƒ¼ã®ã‚ˆã†ãªãƒ©ãƒ™ãƒ«ã§ã‚‚å…¨ã¦ã®æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚

"""
        + get_prompt_criteria_text(["distinctiveness"])
        + """
å‡ºåŠ›å½¢å¼ã¯å¿…ãš JSON å½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
å‡ºåŠ›å½¢å¼ï¼š
{
  "1_1": {
    "distinctiveness": 5
  },
  "1_2": {
    "distinctiveness": 4
  },
  "distinctiveness_comment": "å…¨ä½“ã‚’é€šã˜ã¦ã€AIæŠ€è¡“ã¸ã®æœŸå¾…ã€ã¨ã„ã†å‰æãŒå…±é€šã—ã¦ãŠã‚Šã€å¤šãã®æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ãŒç¤¾ä¼šçš„èª²é¡Œã¸ã®AIã®å¿œç”¨å¯èƒ½æ€§ã‚’æ‰±ã£ã¦ã„ã‚‹ã€‚ãã®ä¸­ã§ã€ç‰©æµãƒ»äº¤é€šã‚„åŒ»ç™‚ã€æ•™è‚²ã¨ã„ã£ãŸå…·ä½“çš„ãªå¿œç”¨åˆ†é‡ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã¯ç›¸å¯¾çš„ã«å·®ç•°æ€§ãŒé«˜ã„ã€‚ä¸€æ–¹ã€æŠ½è±¡çš„ãªAIã®åˆ©ç‚¹ã‚’ç¹°ã‚Šè¿”ã™æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§ã¯å†…å®¹ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãŸã‚ã€ä»Šå¾Œã¯ãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚Šç„¦ç‚¹ã®é•ã„ã‚’æ˜ç¢ºã«ã™ã‚‹å·¥å¤«ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚"
}
"""
    )


def get_prompt_cluster() -> str:
    return (
        """ä»¥ä¸‹ã®ï¼“æŒ‡æ¨™ã«ã¤ã„ã¦ã€1ã€œ5 ç‚¹ã§è©•ä¾¡ã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã¯ä¸‹è¨˜ã®åŸºæº–ã«æ²¿ã£ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
ãã®æ ¹æ‹ ã¨ãªã‚‹ç°¡æ½”ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’1ã€œ2æ–‡ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        + get_prompt_criteria_text(["clarity", "coherence", "consistency"])
        + """
å‡ºåŠ›å½¢å¼ã¯å¿…ãš JSON å½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
å‡ºåŠ›å½¢å¼ï¼š
{
    "clarity": 5,
    "coherence": 5,
    "consistency": 5,
    "comment": "ç’°å¢ƒå½±éŸ¿è©•ä¾¡ã®é€æ˜æ€§ã¨ä¿¡é ¼æ€§ã‚’å¼·èª¿ã—ã¦ãŠã‚Šã€æ„è¦‹ã‚‚æ˜ç¢ºã§ä¸€è²«ã—ã¦ã„ã‚‹ã€‚"
}
"""
    )


def get_prompt_header_all_criteria() -> str:
    return (
        """ä»¥ä¸‹ã®ï¼”æŒ‡æ¨™ã«ã¤ã„ã¦ã€å„æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ 1ã€œ5 ç‚¹ã§è©•ä¾¡ã—ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã¯ä¸‹è¨˜ã®åŸºæº–ã«æ²¿ã£ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

"""
        + get_prompt_criteria_text(
            ["clarity", "coherence", "distinctiveness", "consistency"]
        )
        + """
ã¾ãŸã€å„æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã«ã¯ç°¡æ½”ãªã‚³ãƒ¡ãƒ³ãƒˆï¼ˆcommentï¼‰ã‚‚å¿…ãšè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
ã‚¹ã‚³ã‚¢ã®æ ¹æ‹ ã‚„æ°—ã¥ã„ãŸæ”¹å–„ç‚¹ãƒ»ç‰¹å¾´ãªã©ã‚’1ã€œ2æ–‡ã§ã‚ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ã¯å¿…ãš JSON å½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
å‡ºåŠ›å½¢å¼ï¼š
{
  "1_1": {
    "clarity": 5,
    "coherence": 5,
    "distinctiveness": 5,
    "consistency": 5,
    "comment": "ç’°å¢ƒå½±éŸ¿è©•ä¾¡ã®é€æ˜æ€§ã¨ä¿¡é ¼æ€§ã‚’å¼·èª¿ã—ã¦ãŠã‚Šã€æ„è¦‹ã‚‚æ˜ç¢ºã§ä¸€è²«ã—ã¦ã„ã‚‹ã€‚"
  },
  ...
  "distinctiveness_comment": "å…¨ä½“ã‚’é€šã˜ã¦ã€AIæŠ€è¡“ã¸ã®æœŸå¾…ã€ã¨ã„ã†å‰æãŒå…±é€šã—ã¦ãŠã‚Šã€å¤šãã®æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ãŒç¤¾ä¼šçš„èª²é¡Œã¸ã®AIã®å¿œç”¨å¯èƒ½æ€§ã‚’æ‰±ã£ã¦ã„ã‚‹ã€‚ãã®ä¸­ã§ã€ç‰©æµãƒ»äº¤é€šã‚„åŒ»ç™‚ã€æ•™è‚²ã¨ã„ã£ãŸå…·ä½“çš„ãªå¿œç”¨åˆ†é‡ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—ã¯ç›¸å¯¾çš„ã«å·®ç•°æ€§ãŒé«˜ã„ã€‚ä¸€æ–¹ã€æŠ½è±¡çš„ãªAIã®åˆ©ç‚¹ã‚’ç¹°ã‚Šè¿”ã™æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§ã¯å†…å®¹ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãŸã‚ã€ä»Šå¾Œã¯ãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚Šç„¦ç‚¹ã®é•ã„ã‚’æ˜ç¢ºã«ã™ã‚‹å·¥å¤«ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚"
}
"""
    )


def format_prompt_for_all_criteria(cluster_data: dict) -> str:
    prompt = get_prompt_header_all_criteria()
    for cluster_id, data in cluster_data.items():
        prompt += "\n" + "=" * 30 + f"\nã€æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—IDã€‘{cluster_id}\n"
        prompt += f"ã€ãƒ©ãƒ™ãƒ«ã€‘{data['label']}\n"
        prompt += f"ã€èª¬æ˜ã€‘\n{data['description']}\n"
        prompt += "ã€æ„è¦‹ã€‘\n"
        for arg in data["arguments"]:
            prompt += f"- {arg}\n"
    return prompt


def evaluate_all_criteria_prompt_only(cluster_data: dict, output_path: Path = None):
    prompt = format_prompt_for_all_criteria(cluster_data)
    if output_path:
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(prompt)
        print(f"ğŸ“„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    else:
        print(prompt)


def load_cluster_data(dataset_path: Path, level: int, max_samples: int) -> dict:
    pd.read_csv(dataset_path / "args.csv")
    labels_df = pd.read_csv(dataset_path / "hierarchical_merge_labels.csv")
    clusters_df = pd.read_csv(dataset_path / "hierarchical_clusters.csv")

    cluster_col = f"cluster-level-{level}-id"
    cluster_data = {}

    all_args = {}
    for _, row in labels_df[labels_df["level"] == level].iterrows():
        cluster_id = row["id"]
        label = row["label"]
        description = row["description"]
        cluster_args = clusters_df[clusters_df[cluster_col] == cluster_id][
            "argument"
        ].tolist()
        all_args[cluster_id] = {
            "label": label,
            "description": description,
            "arguments": cluster_args,
        }

    total_clusters = len(all_args)
    total_items = sum(len(v["arguments"]) for v in all_args.values())

    if max_samples < total_clusters:
        raise ValueError(
            f"max-samples({max_samples}) is less than number of clusters({total_clusters})"
        )

    if total_items > max_samples:
        print(
            f"âš ï¸ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ {total_items} ä»¶ãŒ max-samples({max_samples}) ã‚’è¶…ãˆã¦ã„ã‚‹ãŸã‚ã€ä¸€éƒ¨æŠœç²‹ã•ã‚Œã¾ã™ã€‚"
        )

    remaining_budget = max_samples - total_clusters

    for cid, data in all_args.items():
        arg_count = len(data["arguments"])
        ratio = arg_count / total_items if total_items else 0
        extra = int(ratio * remaining_budget)
        count = min(arg_count, 1 + extra)
        cluster_data[cid] = {
            "label": data["label"],
            "description": data["description"],
            "arguments": data["arguments"][:count],
        }

    return cluster_data


def format_batch_prompt_for_ccd(cluster_data: dict) -> str:
    prompt = get_prompt_batch()
    for cluster_id, data in cluster_data.items():
        prompt += "\n" + "=" * 30 + f"\nã€æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—IDã€‘{cluster_id}\n"
        prompt += f"ã€ãƒ©ãƒ™ãƒ«ã€‘{data['label']}\n"
        prompt += f"ã€èª¬æ˜ã€‘\n{data['description']}\n"
    return prompt


def format_prompt_for_consistency(cluster_id: str, data: dict) -> str:
    prompt = get_prompt_cluster()
    prompt += f"\nã€æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—IDã€‘{cluster_id}\n"
    prompt += f"ã€ãƒ©ãƒ™ãƒ«ã€‘{data['label']}\n"
    prompt += f"ã€èª¬æ˜ã€‘\n{data['description']}\n"
    prompt += "ã€æ„è¦‹ã€‘\n"
    for arg in data["arguments"]:
        prompt += f"- {arg}\n"
    return prompt


def evaluate_batch_clarity_coherence_distinctiveness(
    cluster_data: dict, model: str, mode: str
) -> dict:
    if mode == "print":
        prompt = format_batch_prompt_for_ccd(cluster_data)
        print(prompt)
        return {}

    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯è©•ä¾¡è€…ã§ã™ã€‚"},
        {"role": "user", "content": format_batch_prompt_for_ccd(cluster_data)},
    ]
    try:
        response = request_to_chat_openai(messages=messages, model=model, is_json=True)
        results = json.loads(response)
        for cluster_id in cluster_data:
            if cluster_id in results:
                results[cluster_id]["label"] = cluster_data[cluster_id]["label"]
            else:
                print(
                    f"âš ï¸ æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ— {cluster_id} ã®è©•ä¾¡çµæœãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                )
        return results
    except Exception as e:
        print(f"âŒ ãƒãƒƒãƒè©•ä¾¡ã«å¤±æ•—: {e}")
        return {}


def evaluate_consistency_per_cluster(cluster_data: dict, model: str) -> dict:
    results = {}
    for cluster_id, data in cluster_data.items():
        prompt = format_prompt_for_consistency(cluster_id, data)
        messages = [
            {"role": "system", "content": "ã‚ãªãŸã¯è©•ä¾¡è€…ã§ã™ã€‚"},
            {"role": "user", "content": prompt},
        ]
        try:
            response = request_to_chat_openai(
                messages=messages, model=model, is_json=True
            )
            result = json.loads(response)
            results[cluster_id] = result
        except Exception as e:
            print(f"âŒ æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ— {cluster_id} ã®Consistencyè©•ä¾¡ã«å¤±æ•—: {e}")
    return results


def merge_ccd_and_consistency(ccd: dict, consistency: dict) -> dict:
    merged = {}
    for cluster_id in ccd:
        if isinstance(ccd[cluster_id], dict) and isinstance(
            consistency.get(cluster_id), dict
        ):
            merged[cluster_id] = {
                **ccd.get(cluster_id, {}),
                **consistency.get(cluster_id, {}),
            }
    # distinctiveness_comment ã®ã‚ˆã†ãªè£œè¶³ãƒ‡ãƒ¼ã‚¿ã‚‚æ®‹ã—ãŸã„å ´åˆï¼š
    for key in ccd:
        if key not in merged and not isinstance(ccd[key], dict):
            merged[key] = ccd[key]
    return merged


def save_results(results: dict, output_path: Path):
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"âœ“ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


def load_cluster_data(dataset_path: Path, level: int, max_samples: int) -> dict:
    pd.read_csv(dataset_path / "args.csv")
    labels_df = pd.read_csv(dataset_path / "hierarchical_merge_labels.csv")
    clusters_df = pd.read_csv(dataset_path / "hierarchical_clusters.csv")

    cluster_col = f"cluster-level-{level}-id"
    cluster_data = {}

    all_args = {}
    for _, row in labels_df[labels_df["level"] == level].iterrows():
        cluster_id = row["id"]
        label = row["label"]
        description = row["description"]
        cluster_args = clusters_df[clusters_df[cluster_col] == cluster_id][
            "argument"
        ].tolist()
        all_args[cluster_id] = {
            "label": label,
            "description": description,
            "arguments": cluster_args,
        }

    total_clusters = len(all_args)
    total_items = sum(len(v["arguments"]) for v in all_args.values())

    if max_samples < total_clusters:
        raise ValueError(
            f"max-samples({max_samples}) is less than number of clusters({total_clusters})"
        )

    if total_items > max_samples:
        print(
            f"âš ï¸ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ {total_items} ä»¶ãŒ max-samples({max_samples}) ã‚’è¶…ãˆã¦ã„ã‚‹ãŸã‚ã€ä¸€éƒ¨æŠœç²‹ã•ã‚Œã¾ã™ã€‚"
        )

    remaining_budget = max_samples - total_clusters

    for cid, data in all_args.items():
        arg_count = len(data["arguments"])
        ratio = arg_count / total_items if total_items else 0
        extra = int(ratio * remaining_budget)
        count = min(arg_count, 1 + extra)
        cluster_data[cid] = {
            "label": data["label"],
            "description": data["description"],
            "arguments": data["arguments"][:count],
        }

    return cluster_data


def main():
    parser = argparse.ArgumentParser(description="æ„è¦‹ã‚°ãƒ«ãƒ¼ãƒ—æ•´åˆæ€§è©•ä¾¡ï¼ˆLLMä½¿ç”¨ï¼‰")
    parser.add_argument("--dataset", required=True, help="ä¾‹: example")
    parser.add_argument("--level", type=int, default=1)
    parser.add_argument("--max-samples", type=int, default=1000)
    parser.add_argument("--mode", choices=["api", "print"], default="api")
    parser.add_argument("--model", default="gpt-4o-mini")
    args = parser.parse_args()

    dataset_path = Path("inputs") / args.dataset
    output_dir = Path("inputs") / args.dataset  # ä»–ã®å‡¦ç†ã®inputã«ãªã‚‹ã®ã§inputsã«ã—ãŸ
    cluster_data = load_cluster_data(dataset_path, args.level, args.max_samples)

    if args.mode == "print":
        output_path = Path("outputs") / args.dataset / f"prompt_level{args.level}.txt"
        evaluate_all_criteria_prompt_only(cluster_data, output_path)
        return
    ccd_result = evaluate_batch_clarity_coherence_distinctiveness(
        cluster_data, args.model, args.mode
    )
    consistency_result = evaluate_consistency_per_cluster(cluster_data, args.model)

    if args.mode == "api":
        save_results(
            ccd_result,
            output_dir / f"evaluation_consistency_llm_level{args.level}_ccd.json",
        )
        save_results(
            consistency_result,
            output_dir
            / f"evaluation_consistency_llm_level{args.level}_consistency.json",
        )

        # çµ±åˆçµæœã®ä¿å­˜
        merged = merge_ccd_and_consistency(ccd_result, consistency_result)
        save_results(
            merged, output_dir / f"evaluation_consistency_llm_level{args.level}.json"
        )


if __name__ == "__main__":
    main()
