import argparse
import subprocess
import sys
from pathlib import Path


def run_command(command, description):
    print(f"\n=== {description} ===")
    result = subprocess.run(command, shell=True)
    if result.returncode != 0:
        print(f"âŒ {description} ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(result.returncode)


def all_exist(paths):
    return all(p.exists() for p in paths)


def script_path(script_name):
    # ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‘¼ã³å‡ºã™
    return str((Path(__file__).parent / script_name).resolve())


def main():
    parser = argparse.ArgumentParser(description="ã‚¯ãƒ©ã‚¹ã‚¿è©•ä¾¡ä¸€æ‹¬å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument("dataset", help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDï¼ˆä¾‹: 2ï¼‰")
    parser.add_argument("--level", choices=["1", "2", "both"], default="both", help="è©•ä¾¡ãƒ¬ãƒ™ãƒ«ï¼ˆ1, 2, bothï¼‰")
    parser.add_argument("--max-samples", type=int, help="LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹æœ€å¤§æ„è¦‹æ•°ï¼ˆçœç•¥å¯ï¼‰")
    parser.add_argument("--mode", choices=["api", "print"], default="api", help="LLMè©•ä¾¡ã®å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆapi or printï¼‰")
    parser.add_argument("--model", help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: gpt-4oï¼‰")
    args = parser.parse_args()

    dataset = args.dataset
    level_option = args.level
    output_dir = Path("output") / dataset

    levels = [1, 2] if level_option == "both" else [int(level_option)]

    # mode=print ã®å ´åˆã¯å…ˆã«LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡ºåŠ›ã®ã¿è¡Œã„ã€çµæœã‚’ä½¿ã†ã‚ˆã†ã«æ¡ˆå†…
    if args.mode == "print":
        for level in levels:
            print(f"\n=== ã‚¹ãƒ†ãƒƒãƒ—: LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡ºåŠ›ï¼ˆlevel {level}ï¼‰ ===")

            # prompt_level{level}.txt ã®å‡ºåŠ›ã‚’å‰æã¨ã—ã¦è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ä»»ã›ã‚‹
            cmd = (
                f"python {script_path('evaluation_consistency_llm.py')} "
                f"--dataset {dataset} --level {level} --mode print"
            )
            if args.max_samples:
                cmd += f" --max-samples {args.max_samples}"
            if args.model:
                cmd += f" --model {args.model}"

            run_command(cmd, f"LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡ºåŠ›ï¼ˆlevel {level}ï¼‰")

            print(f"ğŸ“„ å®šæ€§è©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ output/{dataset}/prompt_level{level}.txt ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            print(f"ğŸ’¾ å®Ÿè¡Œçµæœã‚’ output/{dataset}/evaluation_consistency_llm_level{level}.json ã«ä¿å­˜ã™ã‚Œã°ã€CSVã‚„HTMLã§åˆ©ç”¨ã§ãã¾ã™ã€‚")
        return

    for level in levels:
        print(f"\n=== ã‚¹ãƒ†ãƒƒãƒ—1: ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆlevel {level}ï¼‰ ===")
        required_files = [
            output_dir / f"silhouette_umap_level{level}_clusters.json",
            output_dir / f"silhouette_umap_level{level}_points.json",
            output_dir / f"silhouette_embedding_level{level}_clusters.json",
            output_dir / f"silhouette_embedding_level{level}_points.json"
        ]
        if all_exist(required_files):
            for f in required_files:
                print(f"âœ… å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {f}")
        else:
            cmd = f"python {script_path('evaluate_silhouette_score.py')} --dataset {dataset} --level {level} --source both"
            run_command(cmd, f"ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆlevel {level}ï¼‰")

    for level in levels:
        print(f"\n=== ã‚¹ãƒ†ãƒƒãƒ—2: LLMè©•ä¾¡ï¼ˆlevel {level}ï¼‰ ===")
        out_path = output_dir / f"evaluation_consistency_llm_level{level}.json"
        if out_path.exists():
            print(f"âœ… å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {out_path}")
        else:
            cmd = (
                f"python {script_path('evaluation_consistency_llm.py')} "
                f"--dataset {dataset} --level {level} --mode {args.mode}"
            )
            if args.max_samples:
                cmd += f" --max-samples {args.max_samples}"
            if args.model:
                cmd += f" --model {args.model}"

            run_command(cmd, f"LLMè©•ä¾¡ï¼ˆlevel {level}ï¼‰")

    print(f"\n=== ã‚¹ãƒ†ãƒƒãƒ—3: CSVå‡ºåŠ› ===")
    run_command(f"python {script_path('generate_csv.py')} {dataset}", "CSVå‡ºåŠ›")
    print(f"âœ“ CSVå‡ºåŠ›å®Œäº†:")
    print(f" - ã‚¯ãƒ©ã‚¹ã‚¿: {output_dir / 'cluster_evaluation.csv'}")
    print(f" - æ„è¦‹:     {output_dir / 'comment_evaluation.csv'}")

    print(f"\n=== ã‚¹ãƒ†ãƒƒãƒ—4: HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ===")
    run_command(f"python {script_path('generate_html.py')} {dataset}", "HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    print(f"âœ“ HTMLå‡ºåŠ›å®Œäº†: {output_dir / 'report.html'}")


if __name__ == "__main__":
    main()
